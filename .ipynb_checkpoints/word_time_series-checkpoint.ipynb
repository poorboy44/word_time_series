{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook takes in ngram time series data produced from a MR job\n",
    "The assumed format is:\n",
    "\n",
    "2\t(2013-01-01 ,#dead)\n",
    "\n",
    "ie.. word \\t (date, term)\n",
    "\n",
    "We parse this data and fit a linear trend model to each term\n",
    "Through clever use of interaction terms in statsmodels we can do this in 1 shot\n",
    "\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import gzip\n",
    "import string\n",
    "import re\n",
    "from time import time\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "##read in stopwrods file\n",
    "stopwords=[]\n",
    "with open('stopwords.txt', 'r') as stop_fn:\n",
    "    for line in stop_fn:\n",
    "       stopwords.append(line.strip().replace('\"', '')) \n",
    "print(\"read in {} stopwords\".format(len(stopwords)))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0=time()\n",
    "line_num=0\n",
    "data_for_df=[]\n",
    "with open('/mnt/snelson/word_time_series/unzipped_word_time_series.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line_num+=1\n",
    "        try:\n",
    "            num_test_recs=1000\n",
    "            #if line_num>num_test_recs:\n",
    "            #    break\n",
    "            data=line.split('\\t')\n",
    "            count=data[0]\n",
    "            mytuple=[x.translate(None, \")(\").strip() for x in re.split(',', data[1], maxsplit=1)]\n",
    "            dt, term=mytuple\n",
    "            dt=dt.strip()\n",
    "            term=term.strip()\n",
    "            count=int(count)\n",
    "            ## check if date is correct\n",
    "            pattern=re.compile('20[0-9]{2}-[0-9]{2}-[0-9]{2}')\n",
    "            if term not in stopwords and len(mytuple)==2 and len(dt)==10 and pattern.search(dt):\n",
    "                dt_list = dt.split(\"-\")\n",
    "                guess_date = int(int(dt_list[1])-1)*31 + int(dt_list[2])\n",
    "                #dt_days=(datetime.strptime(dt, '%Y-%m-%d') - datetime.strptime('2013-01-01', '%Y-%m-%d')).days\n",
    "                data_for_df.append([guess_date, term, count])\n",
    "        except:\n",
    "            print(\"error on line {}: {}\".format(line_num, line))\n",
    "            continue\n",
    "\n",
    "#pickle data for later use\n",
    "#df.to_pickle('df.pkl')\n",
    "t1=time()\n",
    "tot=(t1-t0)/60\n",
    "print(\"time to run test data:{} minutes\".format(tot))\n",
    "print(\"estimated time to run total:{} minutes\".format(tot*(15061489/num_test_recs) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert lsit of lists to a df\n",
    "df=pd.DataFrame(data_for_df, columns=['dt', 'term', 'count'])\n",
    "#df.dt=pd.to_datetime(df.dt, format='%Y-%m-%d')\n",
    "df=df.drop_duplicates()\n",
    "df=df.groupby(['dt', 'term'])['count'].sum().reset_index()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle data for later use\n",
    "#df.to_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## formatting\n",
    "print(df.columns)\n",
    "print(df.head(n=5))\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#number of unique terms in the data\n",
    "unique_terms=df.term.unique()\n",
    "print(unique_terms)\n",
    "print(len(unique_terms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# terms with more than 500 mentions\n",
    "term_count=df.groupby(['term'])['count'].sum()\n",
    "print(len(term_count[term_count>500]))\n",
    "print(term_count[term_count>500])\n",
    "print(term_count[term_count>500].index[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## filter down data set to only include terms with more than 500 mentions -- ~4000 unique terms\n",
    "## 1.3M rows of data\n",
    "df2=df[df.term.isin(term_count[term_count>500].index.values)]\n",
    "print(len(df2))\n",
    "print(len(df2.term.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## filter to terms with more than 30 days of data\n",
    "## would be nice if this was consecutive days \n",
    "num_days_by_term=df2.groupby(['term']).size()\n",
    "num_days_by_term.sort(ascending=False)\n",
    "print(num_days_by_term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run regression on top 100 terms due to memory issues\n",
    "df3=df2[df2.term.isin(num_days_by_term[:1].index.values)]\n",
    "print(df3.shape)\n",
    "print df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_days_by_term.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## fit *ALL* models at once  using interaction terms\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "t0=time()\n",
    "results={}\n",
    "for i in range(len(num_days_by_term.index)):\n",
    "    df3=df2[df2.term==num_days_by_term.index[i]]\n",
    "    results[i] = smf.ols(formula='count ~ C(term) + C(term)*dt', data=df3).fit()\n",
    "t1=time()\n",
    "print(\"running time:{}\".format(t1-t0))\n",
    "#print(\"estimated total running time:{} minutes\".format((t1-t0)/60*4000))\n",
    "#print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## parse out results\n",
    "a=[results[i].params['dt'] for i in results]\n",
    "b=num_days_by_term.index.values\n",
    "c=pd.DataFrame(zip(b,a), columns=['term', 'coef'])\n",
    "c=c.sort(['coef'], ascending=False)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test plot\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "def plotit(i, term):\n",
    "    test=df2[df2.term==term]\n",
    "    test1=pd.Series(data=test['count'].values, index=test['dt'])\n",
    "    #test1.plot(title=term)\n",
    "    plt.figure(); ax=test1.plot(title=term);\n",
    "    ax.set_xlabel(\"day\")\n",
    "    ax.set_ylabel(\"count/day\")\n",
    "    pdf.savefig()\n",
    "    #plt.savefig('./figs/{}.pdf'.format(i))\n",
    "    plt.close()\n",
    "with PdfPages('multipage_pdf.pdf') as pdf:\n",
    "    for i, term in enumerate(c.term.values[:200]):\n",
    "        plotit(i, term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
